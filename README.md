# **RESULTS:**
## **The entire log for the run:**


```Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
<Figure size 640x480 with 1 Axes>
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
<Figure size 640x480 with 1 Axes>
<Figure size 640x480 with 1 Axes>
Epoch: 0
Start steps:
0
Total Steps:
795
/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,
[18/1582 (1%)]	Loss: 18.452665	Class Loss: 1.179685	MMD Loss: 17.272980
[38/1582 (2%)]	Loss: 19.223324	Class Loss: 4.077172	MMD Loss: 15.146151
[58/1582 (4%)]	Loss: 37.705292	Class Loss: 22.579536	MMD Loss: 15.125757
[78/1582 (5%)]	Loss: 28.061596	Class Loss: 11.507112	MMD Loss: 16.554483
[98/1582 (6%)]	Loss: 28.628393	Class Loss: 13.310719	MMD Loss: 15.317675
[118/1582 (7%)]	Loss: 14.585811	Class Loss: 0.000252	MMD Loss: 14.585559
[138/1582 (9%)]	Loss: 14.063713	Class Loss: 0.000000	MMD Loss: 14.063713
[158/1582 (10%)]	Loss: 14.208440	Class Loss: 0.000000	MMD Loss: 14.208440
[178/1582 (11%)]	Loss: 14.321932	Class Loss: 0.000000	MMD Loss: 14.321932
[198/1582 (13%)]	Loss: 124.682480	Class Loss: 110.404785	MMD Loss: 14.277695
[218/1582 (14%)]	Loss: 43.923553	Class Loss: 31.397892	MMD Loss: 12.525660
[238/1582 (15%)]	Loss: 17.342131	Class Loss: 5.339587	MMD Loss: 12.002543
[258/1582 (16%)]	Loss: 44.695858	Class Loss: 33.880444	MMD Loss: 10.815414
[278/1582 (18%)]	Loss: 11.988942	Class Loss: 0.000037	MMD Loss: 11.988905
[298/1582 (19%)]	Loss: 16.606434	Class Loss: 4.003784	MMD Loss: 12.602650
[318/1582 (20%)]	Loss: 21.454151	Class Loss: 10.199931	MMD Loss: 11.254219
[338/1582 (21%)]	Loss: 31.018057	Class Loss: 19.347733	MMD Loss: 11.670324
[358/1582 (23%)]	Loss: 10.644520	Class Loss: 0.000000	MMD Loss: 10.644520
[378/1582 (24%)]	Loss: 37.970646	Class Loss: 26.323788	MMD Loss: 11.646858
[398/1582 (25%)]	Loss: 39.052689	Class Loss: 28.621271	MMD Loss: 10.431416
[418/1582 (26%)]	Loss: 30.421951	Class Loss: 18.943808	MMD Loss: 11.478145
[438/1582 (28%)]	Loss: 24.396370	Class Loss: 13.652049	MMD Loss: 10.744322
[458/1582 (29%)]	Loss: 17.185646	Class Loss: 5.786125	MMD Loss: 11.399521
[478/1582 (30%)]	Loss: 11.037229	Class Loss: 1.161996	MMD Loss: 9.875233
[498/1582 (31%)]	Loss: 20.720907	Class Loss: 13.123100	MMD Loss: 7.597807
[518/1582 (33%)]	Loss: 17.724947	Class Loss: 6.556696	MMD Loss: 11.168251
[538/1582 (34%)]	Loss: 35.605698	Class Loss: 25.174839	MMD Loss: 10.430861
[558/1582 (35%)]	Loss: 10.020905	Class Loss: 0.000000	MMD Loss: 10.020905
[578/1582 (37%)]	Loss: 11.655072	Class Loss: 0.000018	MMD Loss: 11.655054
[598/1582 (38%)]	Loss: 24.305973	Class Loss: 14.001700	MMD Loss: 10.304272
[618/1582 (39%)]	Loss: 33.863281	Class Loss: 23.735950	MMD Loss: 10.127331
[638/1582 (40%)]	Loss: 14.283817	Class Loss: 5.760735	MMD Loss: 8.523083
[658/1582 (42%)]	Loss: 39.257362	Class Loss: 28.233366	MMD Loss: 11.023995
[678/1582 (43%)]	Loss: 42.128689	Class Loss: 32.101349	MMD Loss: 10.027340
[698/1582 (44%)]	Loss: 60.808704	Class Loss: 50.257599	MMD Loss: 10.551105
[718/1582 (45%)]	Loss: 46.157818	Class Loss: 36.498383	MMD Loss: 9.659435
[738/1582 (47%)]	Loss: 28.667271	Class Loss: 19.598701	MMD Loss: 9.068570
[758/1582 (48%)]	Loss: 9.149587	Class Loss: 0.000000	MMD Loss: 9.149587
[778/1582 (49%)]	Loss: 49.921822	Class Loss: 37.993202	MMD Loss: 11.928619
[798/1582 (50%)]	Loss: 32.639740	Class Loss: 21.317762	MMD Loss: 11.321979
[818/1582 (52%)]	Loss: 10.796782	Class Loss: 0.000000	MMD Loss: 10.796782
[838/1582 (53%)]	Loss: 11.271255	Class Loss: 2.194613	MMD Loss: 9.076643
[858/1582 (54%)]	Loss: 9.883801	Class Loss: 0.000000	MMD Loss: 9.883801
[878/1582 (55%)]	Loss: 8.873091	Class Loss: 0.000000	MMD Loss: 8.873091
[898/1582 (57%)]	Loss: 16.510468	Class Loss: 6.828483	MMD Loss: 9.681986
[918/1582 (58%)]	Loss: 23.435417	Class Loss: 11.268189	MMD Loss: 12.167229
[938/1582 (59%)]	Loss: 15.896799	Class Loss: 6.017412	MMD Loss: 9.879387
[958/1582 (61%)]	Loss: 15.057953	Class Loss: 4.375063	MMD Loss: 10.682890
[978/1582 (62%)]	Loss: 19.359295	Class Loss: 10.712847	MMD Loss: 8.646449
[998/1582 (63%)]	Loss: 36.296497	Class Loss: 24.658907	MMD Loss: 11.637591
[1018/1582 (64%)]	Loss: 11.599072	Class Loss: 0.000000	MMD Loss: 11.599072
[1038/1582 (66%)]	Loss: 48.699463	Class Loss: 39.709900	MMD Loss: 8.989563
[1058/1582 (67%)]	Loss: 31.280394	Class Loss: 23.095341	MMD Loss: 8.185053
[1078/1582 (68%)]	Loss: 41.018196	Class Loss: 31.236046	MMD Loss: 9.782149
[1098/1582 (69%)]	Loss: 16.883682	Class Loss: 8.975368	MMD Loss: 7.908314
[1118/1582 (71%)]	Loss: 58.529362	Class Loss: 49.229088	MMD Loss: 9.300274
[1138/1582 (72%)]	Loss: 21.599197	Class Loss: 10.842902	MMD Loss: 10.756296
[1158/1582 (73%)]	Loss: 10.088330	Class Loss: 0.000000	MMD Loss: 10.088330
[1178/1582 (74%)]	Loss: 14.695067	Class Loss: 5.217366	MMD Loss: 9.477701
[1198/1582 (76%)]	Loss: 37.681595	Class Loss: 28.407295	MMD Loss: 9.274299
[1218/1582 (77%)]	Loss: 16.271824	Class Loss: 7.130637	MMD Loss: 9.141188
[1238/1582 (78%)]	Loss: 54.510807	Class Loss: 44.532467	MMD Loss: 9.978339
[1258/1582 (80%)]	Loss: 10.018974	Class Loss: 0.000000	MMD Loss: 10.018974
[1278/1582 (81%)]	Loss: 45.970009	Class Loss: 36.278206	MMD Loss: 9.691801
[1298/1582 (82%)]	Loss: 25.006493	Class Loss: 15.708654	MMD Loss: 9.297837
[1318/1582 (83%)]	Loss: 28.252193	Class Loss: 17.353813	MMD Loss: 10.898380
[1338/1582 (85%)]	Loss: 12.013232	Class Loss: 1.844864	MMD Loss: 10.168368
[1358/1582 (86%)]	Loss: 67.178276	Class Loss: 55.610523	MMD Loss: 11.567750
[1378/1582 (87%)]	Loss: 169.709122	Class Loss: 159.287628	MMD Loss: 10.421493
[1398/1582 (88%)]	Loss: 96.863579	Class Loss: 86.867859	MMD Loss: 9.995720
[1418/1582 (90%)]	Loss: 8.968632	Class Loss: 0.000000	MMD Loss: 8.968632
[1438/1582 (91%)]	Loss: 14.361519	Class Loss: 7.234279	MMD Loss: 7.127240
[1458/1582 (92%)]	Loss: 16.812094	Class Loss: 8.785796	MMD Loss: 8.026298
[1478/1582 (93%)]	Loss: 53.458065	Class Loss: 41.201809	MMD Loss: 12.256257
[1498/1582 (95%)]	Loss: 18.917770	Class Loss: 8.536972	MMD Loss: 10.380797
[1518/1582 (96%)]	Loss: 23.176662	Class Loss: 12.182995	MMD Loss: 10.993668
[1538/1582 (97%)]	Loss: 12.806996	Class Loss: 2.789365	MMD Loss: 10.017632
[1558/1582 (98%)]	Loss: 9.525917	Class Loss: 0.000923	MMD Loss: 9.524994
[1578/1582 (100%)]	Loss: 35.086464	Class Loss: 26.309128	MMD Loss: 8.777338
Time: 308.5405s

Source Accuracy: 200/397 (50.3778%)
Target Accuracy: 189/396 (47.7273%)

<Figure size 640x480 with 1 Axes>
<Figure size 640x480 with 1 Axes>
<Figure size 640x480 with 1 Axes>
